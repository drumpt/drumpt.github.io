<!doctype html><!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: February 1, 2025 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=stylesheet href=/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.018058c879a481473e1c076a8e11c2e5.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Changhun Kim"><meta name=description content="Speaker-adaptive Text-to-Speech (TTS) synthesis has attracted considerable attention due to its broad range of applications, such as personalized voice assistant services. While several approaches have been proposed, they often exhibit high sensitivity to either the quantity or the quality of target speech samples. To address these limitations, we introduce Stable-TTS, a novel speaker-adaptive TTS framework that leverages a small subset of a high-quality pre-training dataset, referred to as prior samples. Specifically, Stable-TTS achieves prosody consistency by leveraging the high-quality prosody of prior samples, while effectively capturing the timbre of the target speaker. Additionally, it employs a prior-preservation loss during fine-tuning to maintain the synthesis ability for prior samples to prevent overfitting on target samples. Extensive experiments demonstrate the effectiveness of Stable-TTS even under limited target speech samples."><link rel=alternate hreflang=en-us href=https://drumpt.github.io/publications/stable-tts/><link rel=canonical href=https://drumpt.github.io/publications/stable-tts/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu3c06ff49a96dc5c4160caa1f4cb0f97d_35271_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu3c06ff49a96dc5c4160caa1f4cb0f97d_35271_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#2c6941"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@wowchemy"><meta property="twitter:creator" content="@wowchemy"><meta property="twitter:image" content="https://drumpt.github.io/publications/stable-tts/featured.png"><meta property="og:site_name" content="Changhun Kim"><meta property="og:url" content="https://drumpt.github.io/publications/stable-tts/"><meta property="og:title" content="Stable-TTS: Stable Speaker-Adaptive Text-to-Speech Synthesis via Prosody Prompting | Changhun Kim"><meta property="og:description" content="Speaker-adaptive Text-to-Speech (TTS) synthesis has attracted considerable attention due to its broad range of applications, such as personalized voice assistant services. While several approaches have been proposed, they often exhibit high sensitivity to either the quantity or the quality of target speech samples. To address these limitations, we introduce Stable-TTS, a novel speaker-adaptive TTS framework that leverages a small subset of a high-quality pre-training dataset, referred to as prior samples. Specifically, Stable-TTS achieves prosody consistency by leveraging the high-quality prosody of prior samples, while effectively capturing the timbre of the target speaker. Additionally, it employs a prior-preservation loss during fine-tuning to maintain the synthesis ability for prior samples to prevent overfitting on target samples. Extensive experiments demonstrate the effectiveness of Stable-TTS even under limited target speech samples."><meta property="og:image" content="https://drumpt.github.io/publications/stable-tts/featured.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="1998-03-20T00:00:00+00:00"><meta property="article:modified_time" content="2024-10-01T00:00:00+00:00"><title>Stable-TTS: Stable Speaker-Adaptive Text-to-Speech Synthesis via Prosody Prompting | Changhun Kim</title><script async defer src=https://buttons.github.io/buttons.js></script></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=c6a254181cf4130699cba3a0f7acd87b><script src=/js/wowchemy-init.min.fe8634e7d00f14d07fb33caf14cc8e55.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Changhun Kim</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Changhun Kim</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#news><span>News</span></a></li><li class=nav-item><a class=nav-link href=/#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#patents><span>Patents</span></a></li><li class=nav-item><a class=nav-link href=/#honors><span>Honors</span></a></li><li class=nav-item><a class=nav-link href=/#teaching><span>Teaching</span></a></li><li class=nav-item><a class=nav-link href=/#service><span>Service</span></a></li><li class=nav-item><a class=nav-link href=/#projects><span>Projects</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"></ul></div></nav></header></div><div class=page-body><article class=article><div class="article-container pt-3"><h1>Stable-TTS: Stable Speaker-Adaptive Text-to-Speech Synthesis via Prosody Prompting</h1><div class=article-metadata><div><span>Wooseok Han</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Minki Kang</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span class=author-highlighted>Changhun Kim</span>, <span>Eunho Yang</span></div><span class=article-date>Mar. 10, 10998</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=https://arxiv.org/abs/2412.20155 target=_blank rel=noopener>Preprint</a>
<a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/publications/stable-tts/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header" href=https://stable-tts.github.io target=_blank rel=noopener>Project</a></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:179px><div style=position:relative><img src=/publications/stable-tts/featured_hu194818159c5f625a6771b3ba8ceaa181_395751_720x2500_fit_q75_h2_lanczos_3.webp width=720 height=179 alt class=featured-image>
<span class=article-header-caption>Image credit: <a href=https://unsplash.com/photos/pLCdAaMFLTE target=_blank rel=noopener><strong>Unsplash</strong></a></span></div></div><div class=article-container><div class=article-style></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fdrumpt.github.io%2Fpublications%2Fstable-tts%2F&amp;text=Stable-TTS%3A+Stable+Speaker-Adaptive+Text-to-Speech+Synthesis+via+Prosody+Prompting" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fdrumpt.github.io%2Fpublications%2Fstable-tts%2F&amp;t=Stable-TTS%3A+Stable+Speaker-Adaptive+Text-to-Speech+Synthesis+via+Prosody+Prompting" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Stable-TTS%3A%20Stable%20Speaker-Adaptive%20Text-to-Speech%20Synthesis%20via%20Prosody%20Prompting&amp;body=https%3A%2F%2Fdrumpt.github.io%2Fpublications%2Fstable-tts%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fdrumpt.github.io%2Fpublications%2Fstable-tts%2F&amp;title=Stable-TTS%3A+Stable+Speaker-Adaptive+Text-to-Speech+Synthesis+via+Prosody+Prompting" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Stable-TTS%3A+Stable+Speaker-Adaptive+Text-to-Speech+Synthesis+via+Prosody+Prompting%20https%3A%2F%2Fdrumpt.github.io%2Fpublications%2Fstable-tts%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Fdrumpt.github.io%2Fpublications%2Fstable-tts%2F&amp;title=Stable-TTS%3A+Stable+Speaker-Adaptive+Text-to-Speech+Synthesis+via+Prosody+Prompting" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=https://drumpt.github.io/><img class="avatar mr-3 avatar-circle" src=/authors/admin/avatar_hu4ffaf8ee58ba3407b626001937d806ef_226814_270x270_fill_q75_lanczos_center.jpg alt="Changhun Kim"></a><div class=media-body><h5 class=card-title><a href=https://drumpt.github.io/>Changhun Kim</a></h5><h6 class=card-subtitle>Machine Learning Researcher</h6><ul class=network-icon aria-hidden=true><li><a href=mailto:changhun.a.kim@gmail.com><i class="fas fa-envelope"></i></a></li><li><a href="https://scholar.google.com/citations?user=mY7KEvAAAAAJ" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://github.com/drumpt target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://www.linkedin.com/in/changhun-kim/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=https://twitter.com/hooni_ne target=_blank rel=noopener><i class="fab fa-x"></i></a></li></ul></div></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer></footer></div></div><script src=/js/vendor-bundle.min.f64289d8217e08e3afcd597d60836062.js></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script>
<script src=/en/js/wowchemy.min.3322c0d94f0e691b0b24c63f4c41064b.js></script></body></html>
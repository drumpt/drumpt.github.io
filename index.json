[{"authors":null,"categories":null,"content":"I am a machine learning researcher at AITRICS, a healthcare AI startup in Korea, where I am fulfilling my alternative military service under Prof. Eunho Yang. Before joining AITRICS, I obtained my master‚Äôs degree in Artificial Intelligence from KAIST, also under the guidance of Prof. Eunho Yang. I completed my bachelor‚Äôs degree in Computer Science and Mathematical Sciences at KAIST as well. I am open to research collaborations globally, including remote opportunities. If you are interested in my work, please feel free to reach out!\nMy long-term research objective is to enhance the out-of-distribution generalization capability of machine learning models, thereby creating trustworthy AI systems that can be reliably deployed in new environments. This multifaceted goal involves ensuring robustness to distribution shifts (domain adaptation and generalization), handling unseen labels (zero-shot learning), and managing unseen tasks (cross-task generalization). During my master‚Äôs program, I focused on test-time adaptation to distribution shifts across various tasks, including 3D point cloud recognition, zero-shot transfer of vision-language models, automatic speech recognition, tabular learning, and time series classification. These experiences have also enabled myself to quickly adapt to new modalities and tasks.\nAt AITRICS, my research centers on improving the generalizability, robustness, and explainability of early prediction models for critical clinical outcomes such as cardiac arrests and in-hospital mortality. I am also interested in parameter- and data-efficient adaptation of deep generative models, such as diffusion models and large multimodal models, to downstream tasks. To achieve these goals, I work on developing practical algorithms that are empirically well-grounded or theoretically provable. Additionally, I am passionate about providing theoretical insights into machine learning models through the lens of probabilistic (Bayesian inference) and statistical (generalization bounds) frameworks.\n","date":1727913600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1727913600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a machine learning researcher at AITRICS, a healthcare AI startup in Korea, where I am fulfilling my alternative military service under Prof. Eunho Yang. Before joining AITRICS, I obtained my master‚Äôs degree in Artificial Intelligence from KAIST, also under the guidance of Prof.","tags":null,"title":"Changhun Kim","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy‚Äôs Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://drumpt.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":[],"categories":null,"content":"","date":1734652800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1734652800,"objectID":"707891daf00c2015d4f6b835562de9d6","permalink":"https://drumpt.github.io/news/stable-tts/","publishdate":"2024-12-20T00:00:00Z","relpermalink":"/news/stable-tts/","section":"news","summary":"","tags":[],"title":"One paper is accepted to ICASSP 2025.","type":"news"},{"authors":[],"categories":null,"content":"","date":1728518400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728518400,"objectID":"6bde8303b16c838d0e77c44164b59564","permalink":"https://drumpt.github.io/news/adaptable-neuripsw/","publishdate":"2024-10-10T00:00:00Z","relpermalink":"/news/adaptable-neuripsw/","section":"news","summary":"","tags":[],"title":"One paper is accepted to NeurIPSW-TRL 2024.","type":"news"},{"authors":["Hyeongwon Jang","Changhun Kim","Eunho Yang"],"categories":null,"content":"","date":1727913600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727913600,"objectID":"85c835be8afcfa11cf188187b7a2f6de","permalink":"https://drumpt.github.io/publications/timing/","publishdate":"1998-03-20T00:00:00Z","relpermalink":"/publications/timing/","section":"publications","summary":"","tags":[],"title":"Timing: Temporality-Aware Integrated Gradients for Time Series Explanation","type":"publications"},{"authors":["Changhun Kim","Joohyung Lee","Kwanhyung Lee","Donghwee Yoon","Eunho Yang"],"categories":null,"content":"","date":1727827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727827200,"objectID":"5ae68f453ab4079bb064d1cc5114a624","permalink":"https://drumpt.github.io/publications/spam/","publishdate":"1998-03-20T00:00:00Z","relpermalink":"/publications/spam/","section":"publications","summary":"","tags":[],"title":"SPAM: Sampling Pattern Meta-Learning for Domain Generalization on Irregular Time Series","type":"publications"},{"authors":["Wooseok Han","Minki Kang","Changhun Kim","Eunho Yang"],"categories":null,"content":"","date":1727740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727740800,"objectID":"c6a254181cf4130699cba3a0f7acd87b","permalink":"https://drumpt.github.io/publications/stable-tts/","publishdate":"1998-03-20T00:00:00Z","relpermalink":"/publications/stable-tts/","section":"publications","summary":"Speaker-adaptive Text-to-Speech (TTS) synthesis has attracted considerable attention due to its broad range of applications, such as personalized voice assistant services. While several approaches have been proposed, they often exhibit high sensitivity to either the quantity or the quality of target speech samples. To address these limitations, we introduce Stable-TTS, a novel speaker-adaptive TTS framework that leverages a small subset of a high-quality pre-training dataset, referred to as prior samples. Specifically, Stable-TTS achieves prosody consistency by leveraging the high-quality prosody of prior samples, while effectively capturing the timbre of the target speaker. Additionally, it employs a prior-preservation loss during fine-tuning to maintain the synthesis ability for prior samples to prevent overfitting on target samples. Extensive experiments demonstrate the effectiveness of Stable-TTS even under limited target speech samples.","tags":[],"title":"Stable-TTS: Stable Speaker-Adaptive Text-to-Speech Synthesis via Prosody Prompting","type":"publications"},{"authors":["Changhun Kim","Taewon Kim","Seungyeon Woo","June Yong Yang","Eunho Yang"],"categories":null,"content":"","date":1727654400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727654400,"objectID":"abb5b18c608bbdbfe3bdd4f91b48e141","permalink":"https://drumpt.github.io/publications/adaptable/","publishdate":"1998-03-20T00:00:00Z","relpermalink":"/publications/adaptable/","section":"publications","summary":"In real-world scenarios, tabular data often suffer from distribution shifts that threaten the performance of machine learning models. Despite its prevalence and importance, handling distribution shifts in the tabular domain remains underexplored due to the inherent challenges within the tabular data itself. In this sense, test-time adaptation (TTA) offers a promising solution by adapting models to target data without accessing source data, crucial for privacy-sensitive tabular domains. However, existing TTA methods either 1) overlook the nature of tabular distribution shifts, often involving label distribution shifts, or 2) impose architectural constraints on the model, leading to a lack of applicability. To this end, we propose AdapTable, a novel TTA framework for tabular data. AdapTable operates in two stages: 1) calibrating model predictions using a shift-aware uncertainty calibrator, and 2) adjusting these predictions to match the target label distribution with a label distribution handler. We validate the effectiveness of AdapTable through theoretical analysis and extensive experiments on various distribution shift scenarios. Our results demonstrate AdapTable's ability to handle various real-world distribution shifts, achieving up to a 16% improvement on the HELOC dataset.","tags":[],"title":"AdapTable: Test-Time Adaptation for Tabular Data via Shift-Aware Uncertainty Calibrator and Label Distribution Handler","type":"publications"},{"authors":["Hajin Shim","Changhun Kim","Eunho Yang"],"categories":null,"content":"","date":1727568e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727568e3,"objectID":"7add84aed3f8bf1a927e65c01337caa6","permalink":"https://drumpt.github.io/publications/cloudfixer/","publishdate":"1998-03-20T00:00:00Z","relpermalink":"/publications/cloudfixer/","section":"publications","summary":"3D point clouds captured from real-world sensors frequently encompass noisy points due to various obstacles, such as occlusion, limited resolution, and variations in scale. These challenges hinder the deployment of pre-trained point cloud recognition models trained on clean point clouds, leading to significant performance degradation. While test-time adaptation (TTA) strategies have shown promising results on this issue in the 2D domain, their application to 3D point clouds remains under-explored. Among TTA methods, an input adaptation approach, which directly converts test instances to the source domain using a pre-trained diffusion model, has been proposed in the 2D domain. Despite its robust TTA performance in practical situations, naively adopting this into the 3D domain may be suboptimal due to the neglect of inherent properties of point clouds, and its prohibitive computational cost. Motivated by these limitations, we propose CloudFixer, a test-time input adaptation method tailored for 3D point clouds, employing a pre-trained diffusion model. Specifically, CloudFixer optimizes geometric transformation parameters with carefully designed objectives that leverage the geometric properties of point clouds. We also substantially improve computational efficiency by avoiding backpropagation through the diffusion model and a prohibitive generation process. Furthermore, we propose an online model adaptation strategy by aligning the original model prediction with that of the adapted input. Extensive experiments showcase the superiority of CloudFixer over various TTA baselines, excelling in handling common corruptions and natural distribution shifts across diverse real-world scenarios. Our code is available at https://github.com/shimazing/CloudFixer.","tags":[],"title":"CloudFixer: Test-Time Adaptation for 3D Point Clouds via Diffusion-Guided Geometric Transformation","type":"publications"},{"authors":[],"categories":null,"content":"","date":1727568e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727568e3,"objectID":"9cf3893725aff130ee5b37350977c562","permalink":"https://drumpt.github.io/news/eccv2024/","publishdate":"2024-07-29T00:00:00Z","relpermalink":"/news/eccv2024/","section":"news","summary":"","tags":[],"title":"I am attending ECCV 2024 in person. See you in Milano!","type":"news"},{"authors":[],"categories":null,"content":"","date":1719792e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719792e3,"objectID":"f3d998a5a95c0903520888714c08d7de","permalink":"https://drumpt.github.io/news/cloudfixer/","publishdate":"2024-07-01T00:00:00Z","relpermalink":"/news/cloudfixer/","section":"news","summary":"","tags":[],"title":"One paper is accepted to ECCV 2024.","type":"news"},{"authors":[],"categories":null,"content":"","date":1718755200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1718755200,"objectID":"00cc5851664b910a435140f0be49e5bd","permalink":"https://drumpt.github.io/news/kosmi2024/","publishdate":"2024-06-19T00:00:00Z","relpermalink":"/news/kosmi2024/","section":"news","summary":"","tags":[],"title":"I am attending KOSMI 2024 in person. See you in Seoul!","type":"news"},{"authors":[],"categories":null,"content":"","date":1713052800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713052800,"objectID":"9824f944d29218e0d86a6af62906177b","permalink":"https://drumpt.github.io/news/icassp2024/","publishdate":"2024-04-14T00:00:00Z","relpermalink":"/news/icassp2024/","section":"news","summary":"","tags":[],"title":"I am attending ICASSP 2024 in person. See you in Seoul!","type":"news"},{"authors":[],"categories":null,"content":"","date":1708646400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1708646400,"objectID":"1ca1a1cfb15582aaf527a8706bd72c01","permalink":"https://drumpt.github.io/news/msgrad/","publishdate":"2024-02-23T00:00:00Z","relpermalink":"/news/msgrad/","section":"news","summary":"","tags":[],"title":"I have completed my master‚Äôs thesis defense and graduated from my master's program.","type":"news"},{"authors":[],"categories":null,"content":"","date":1700438400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1700438400,"objectID":"ce9b5dd519aeb0c779959cfb3594d962","permalink":"https://drumpt.github.io/news/aitrics/","publishdate":"2023-11-20T00:00:00Z","relpermalink":"/news/aitrics/","section":"news","summary":"","tags":[],"title":"I am starting my next research journey as a machine learning researcher at AITRICS.","type":"news"},{"authors":[],"categories":null,"content":"","date":1692489600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692489600,"objectID":"353656628e759ab8f19a2a9d57d4e700","permalink":"https://drumpt.github.io/news/interspeech2023/","publishdate":"2023-08-20T00:00:00Z","relpermalink":"/news/interspeech2023/","section":"news","summary":"","tags":[],"title":"I am attending INTERSPEECH 2023 in person. See you in Dublin!","type":"news"},{"authors":["Wooseok Han","Minki Kang","Changhun Kim","Eunho Yang","Kwang Joon Kim"],"categories":null,"content":"","date":1688515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688515200,"objectID":"6c35ec6c94df9dd37fbd883a01ce6112","permalink":"https://drumpt.github.io/patents/stable-tts/","publishdate":"2023-07-03T00:00:00Z","relpermalink":"/patents/stable-tts/","section":"patents","summary":"","tags":null,"title":"Stable Speaker-Adaptive Text-to-Speech Synthesis via Prosody Prompting","type":"patents"},{"authors":["Changhun Kim","Sangchul Hahn","Kwang Joon Kim"],"categories":null,"content":"","date":1688428800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688428800,"objectID":"5b6bc7dade0152e4740a62b80c08a368","permalink":"https://drumpt.github.io/patents/nle/","publishdate":"2023-07-03T00:00:00Z","relpermalink":"/patents/nle/","section":"patents","summary":"","tags":null,"title":"Method for Providing Explanation for Patient State Prediction and Electronic Apparatus Therefor","type":"patents"},{"authors":["Changhun Kim","Joonhyung Park","Hajin Shim","Eunho Yang"],"categories":null,"content":" ","date":1688342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688342400,"objectID":"5757133f97af0b67ff51a995510f0089","permalink":"https://drumpt.github.io/publications/sgem/","publishdate":"2022-07-03T00:00:00Z","relpermalink":"/publications/sgem/","section":"publications","summary":"Automatic speech recognition (ASR) models are frequently exposed to data distribution shifts in many real-world scenarios, leading to erroneous predictions. To tackle this issue, an existing test-time adaptation (TTA) method has recently been proposed to adapt the pre-trained ASR model on unlabeled test instances without source data. Despite decent performance gain, this work relies solely on naive greedy decoding and performs adaptation across timesteps at a frame level, which may not be optimal given the sequential nature of the model output. Motivated by this, we propose a novel TTA framework, dubbed SGEM, for general ASR models. To treat the sequential output, SGEM first exploits beam search to explore candidate output logits and selects the most plausible one. Then, it utilizes generalized entropy minimization and negative sampling as unsupervised objectives to adapt the model. SGEM achieves state-of-the-art performance for three mainstream ASR models under various domain shifts.","tags":[],"title":"SGEM: Test-Time Adaptation for Automatic Speech Recognition via Sequential-Level Generalized Entropy Minimization","type":"publications"},{"authors":["Eunho Yang","Changhun Kim","Joonhyung Park","Hajin Shim"],"categories":null,"content":"","date":1688342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688342400,"objectID":"cbb5e3cd3d1df6a5852d9df170562524","permalink":"https://drumpt.github.io/patents/sgem/","publishdate":"2023-07-03T00:00:00Z","relpermalink":"/patents/sgem/","section":"patents","summary":"","tags":null,"title":"Test-Time Adaptation for Automatic Speech Recognition via Sequential-Level Generalized Entropy Minimization","type":"patents"},{"authors":[],"categories":null,"content":"","date":1684368e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684368e3,"objectID":"648bd12381411e481f7f27f05ff7b526","permalink":"https://drumpt.github.io/news/sgem/","publishdate":"2023-05-18T00:00:00Z","relpermalink":"/news/sgem/","section":"news","summary":"","tags":[],"title":"One paper is accepted to INTERSPEECH 2023 as an oral presentation.","type":"news"},{"authors":["Changhun Kim","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"import libr print(\u0026#39;hello\u0026#39;) Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It‚Äôs a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more Get Started üëâ Create a new site üìö Personalize your site üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy‚Äôs future ‚ù§Ô∏è As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features ü¶Ñ‚ú®\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you‚Äôll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"1f0185a2a46eb3e0838d0e9905d8f7d0","permalink":"https://drumpt.github.io/blog/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/blog/getting-started/","section":"blog","summary":"Welcome üëã We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"blog"},{"authors":null,"categories":null,"content":"Wowchemy is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you‚Äôll find some examples of the types of technical content that can be rendered with Wowchemy.\nExamples Code Wowchemy supports a Markdown extension for highlighting code syntax. You can customize the styles under the syntax_highlighter option in your config/_default/params.yaml file.\n```python import pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() ``` renders as\nimport pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() Mindmaps Wowchemy supports a Markdown extension for mindmaps.\nSimply insert a Markdown markmap code block and optionally set the height of the mindmap as shown in the example below.\nA simple mindmap defined as a Markdown list:\n```markmap {height=\u0026#34;200px\u0026#34;} - Hugo Modules - wowchemy - wowchemy-plugins-netlify - wowchemy-plugins-netlify-cms - wowchemy-plugins-reveal ``` renders as\n- Hugo Modules - wowchemy - wowchemy-plugins-netlify - wowchemy-plugins-netlify-cms - wowchemy-plugins-reveal A more advanced mindmap with formatting, code blocks, and math:\n```markmap - Mindmaps - Links - [Wowchemy Docs](https://wowchemy.com/docs/) - [Discord Community](https://discord.gg/z8wNYzb) - [GitHub](https://github.com/wowchemy/wowchemy-hugo-themes) - Features - Markdown formatting - **inline** ~~text~~ *styles* - multiline text - `inline code` - ```js console.log(\u0026#39;hello\u0026#39;); console.log(\u0026#39;code block\u0026#39;); ``` - Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ ``` renders as\n- Mindmaps - Links - [Wowchemy Docs](https://wowchemy.com/docs/) - [Discord Community](https://discord.gg/z8wNYzb) - [GitHub](https://github.com/wowchemy/wowchemy-hugo-themes) - Features - Markdown formatting - **inline** ~~text~~ *styles* - multiline text - `inline code` - ```js console.log(\u0026#39;hello\u0026#39;); console.log(\u0026#39;code block\u0026#39;); ``` - Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ Charts Wowchemy supports the popular Plotly format for interactive charts.\nSave your Plotly JSON in your page folder, for example line-chart.json, and then add the {{\u0026lt; chart data=\u0026#34;line-chart\u0026#34; \u0026gt;}} shortcode where you would like the chart to appear.\nDemo:\nYou might also find the Plotly JSON Editor useful.\nMath Wowchemy supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.yaml file.\nTo render inline or block math, wrap your LaTeX math with {{\u0026lt; math \u0026gt;}}$...${{\u0026lt; /math \u0026gt;}} or {{\u0026lt; math \u0026gt;}}$$...$${{\u0026lt; /math \u0026gt;}}, respectively. (We wrap the LaTeX math in the Wowchemy math shortcode to prevent Hugo rendering our math as Markdown. The math shortcode is new in v5.5-dev.)\nExample math block:\n{{\u0026lt; math \u0026gt;}} $$ \\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2} $$ {{\u0026lt; /math \u0026gt;}} renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$ Example inline math {{\u0026lt; math \u0026gt;}}$\\nabla F(\\mathbf{x}_{n})${{\u0026lt; /math \u0026gt;}} renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the math linebreak (\\\\):\n{{\u0026lt; math \u0026gt;}} $$f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$ {{\u0026lt; /math \u0026gt;}} renders as\n$$ f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases} $$ Diagrams Wowchemy supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ``` renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ``` renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ``` renders ‚Ä¶","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"16adc062967a2a9329e4a92d6b1689f3","permalink":"https://drumpt.github.io/blog/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/blog/writing-technical-content/","section":"blog","summary":"Wowchemy is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Markdown","type":"blog"},{"authors":["Changhun Kim"],"categories":[],"content":"from IPython.core.display import Image Image(\u0026#39;https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png\u0026#39;) print(\u0026#34;Welcome to Academic!\u0026#34;) Welcome to Academic! Install Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post\u0026#39;s title date: 2019-09-01 # Put any other Academic metadata here... --- Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post‚Äôs folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=. Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"d90f9beaeb29e53e637a76a024e38951","permalink":"https://drumpt.github.io/blog/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/blog/jupyter/","section":"blog","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"blog"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://drumpt.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"company: KAIST Applied Artificial Intelligence Lab company_logo: company_url: ‚Äúhttps://aai.kaist.ac.kr/\u0026#34; location: Daejeon, South Korea items: - title: Developer date_start: ‚Äú2021-09-07‚Äù date_end: ‚Äú2022-01-11‚Äù\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"fb202e379ab084308260d97ebf12c83e","permalink":"https://drumpt.github.io/experience/aailab/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/experience/aailab/","section":"experience","summary":"company: KAIST Applied Artificial Intelligence Lab company_logo: company_url: ‚Äúhttps://aai.kaist.ac.kr/\" location: Daejeon, South Korea items: - title: Developer date_start: ‚Äú2021-09-07‚Äù date_end: ‚Äú2022-01-11‚Äù","tags":null,"title":"","type":"experience"},{"authors":null,"categories":null,"content":"company: AITRICS company_logo: company_url: ‚Äúhttps://en.aitrics.com/\u0026#34; location: Seoul, South Korea items: - title: Machine Learning Researcher date_start: ‚Äú2023-11-20‚Äù\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7109c194ea8d9921f24d5863dd92e21f","permalink":"https://drumpt.github.io/experience/aitrics/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/experience/aitrics/","section":"experience","summary":"company: AITRICS company_logo: company_url: ‚Äúhttps://en.aitrics.com/\" location: Seoul, South Korea items: - title: Machine Learning Researcher date_start: ‚Äú2023-11-20‚Äù","tags":null,"title":"","type":"experience"},{"authors":null,"categories":null,"content":"company: DeepNatural company_logo: company_url: ‚Äúhttps://deepnatural.ai/\u0026#34; location: Seoul, South Korea items: - title: Machine Learning Engineer date_start: ‚Äú2020-09-14‚Äù date_end: ‚Äú2021-02-26‚Äù\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8d853b86765f9ba55242d6598d22c3eb","permalink":"https://drumpt.github.io/experience/deepnatural/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/experience/deepnatural/","section":"experience","summary":"company: DeepNatural company_logo: company_url: ‚Äúhttps://deepnatural.ai/\" location: Seoul, South Korea items: - title: Machine Learning Engineer date_start: ‚Äú2020-09-14‚Äù date_end: ‚Äú2021-02-26‚Äù","tags":null,"title":"","type":"experience"},{"authors":null,"categories":null,"content":"company: KAIST Machine Learning and Intelligence Lab company_logo: company_url: ‚Äúhttps://mli.kaist.ac.kr/\u0026#34; location: Daejeon, South Korea items: - title: Master‚Äôs Student Researcher date_start: ‚Äú2022-03-02‚Äù date_end: ‚Äú2024-02-27‚Äù - title: Undergraduate Researcher date_start: ‚Äú2021-06-28‚Äù date_end: ‚Äú2022-02-25‚Äù\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"66ff6d168000be963cdf17392082a274","permalink":"https://drumpt.github.io/experience/mlilab/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/experience/mlilab/","section":"experience","summary":"company: KAIST Machine Learning and Intelligence Lab company_logo: company_url: ‚Äúhttps://mli.kaist.ac.kr/\" location: Daejeon, South Korea items: - title: Master‚Äôs Student Researcher date_start: ‚Äú2022-03-02‚Äù date_end: ‚Äú2024-02-27‚Äù - title: Undergraduate Researcher date_start: ‚Äú2021-06-28‚Äù date_end: ‚Äú2022-02-25‚Äù","tags":null,"title":"","type":"experience"},{"authors":null,"categories":null,"content":"company: Netmarble company_logo: company_url: ‚Äúhttps://www.netmarble.net/\u0026#34; location: Seoul, South Korea items: - title: Data Engineer date_start: ‚Äú2019-06-24‚Äù date_end: ‚Äú2019-08-16‚Äù\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"abf859e3ad97f26d3ff23d69b12418fc","permalink":"https://drumpt.github.io/experience/netmarble/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/experience/netmarble/","section":"experience","summary":"company: Netmarble company_logo: company_url: ‚Äúhttps://www.netmarble.net/\" location: Seoul, South Korea items: - title: Data Engineer date_start: ‚Äú2019-06-24‚Äù date_end: ‚Äú2019-08-16‚Äù","tags":null,"title":"","type":"experience"},{"authors":null,"categories":null,"content":"company: KAIST Vehicular Intelligence Lab company_logo: company_url: ‚Äúhttps://vil.kaist.ac.kr/\u0026#34; location: Daejeon, South Korea items: - title: Undergraduate Researcher date_start: ‚Äú2019-10-15‚Äù date_end: ‚Äú2020-08-15‚Äù\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0f069b225ee1d7887ea63c534b15f309","permalink":"https://drumpt.github.io/experience/vil/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/experience/vil/","section":"experience","summary":"company: KAIST Vehicular Intelligence Lab company_logo: company_url: ‚Äúhttps://vil.kaist.ac.kr/\" location: Daejeon, South Korea items: - title: Undergraduate Researcher date_start: ‚Äú2019-10-15‚Äù date_end: ‚Äú2020-08-15‚Äù","tags":null,"title":"","type":"experience"}]